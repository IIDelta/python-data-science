{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # We'll use np.nan for empty cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ds_df = pd.read_parquet(\"Raw_Data/DS.parquet\")\n",
    "    ec_df = pd.read_parquet(\"Raw_data/EC.parquet\")\n",
    "    ie_df = pd.read_parquet(\"Raw_data/IE.parquet\")\n",
    "except:\n",
    "    print(\"Data not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e85931",
   "metadata": {},
   "source": [
    "# Randomization Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Randomization Scheme ---\n",
    "rand_df = pd.read_parquet(\"Raw_Data/randomization_scheme.parquet\")\n",
    "print(\"Randomization scheme loaded:\")\n",
    "print(rand_df.head())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Rename 'Randomization Number' to 'SUBJID' for consistency ---\n",
    "rand_df.rename(columns={'Randomization Number': 'SUBJID'}, inplace=True)\n",
    "\n",
    "# --- Reshape (Melt) the DataFrame ---\n",
    "# Identify the columns that are 'ID variables' (stay as they are)\n",
    "id_vars = ['SUBJID', 'Block Number', 'Sequence']\n",
    "# Identify the columns that are 'value variables' (get unpivoted)\n",
    "value_vars = ['Treatment in Period 1', 'Treatment in Period 2', 'Treatment in Period 3',\n",
    "              'Treatment in Period 4', 'Treatment in Period 5', 'Treatment in Period 6']\n",
    "\n",
    "# Use pd.melt to transform from wide to long\n",
    "rand_long_df = pd.melt(rand_df,\n",
    "                       id_vars=id_vars,\n",
    "                       value_vars=value_vars,\n",
    "                       var_name='Period_Raw', # Name for the new column holding 'Treatment in Period X'\n",
    "                       value_name='Treatment') # Name for the new column holding 'TP1', 'CP', etc.\n",
    "\n",
    "print(\"Randomization data after melting (long format):\")\n",
    "print(rand_long_df.head())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Extract the Period Number ---\n",
    "# We want just the number (1, 2, 3...) from 'Treatment in Period X'.\n",
    "# .str.extract('(\\\\d+)') finds one or more digits and extracts them.\n",
    "# .astype(int) converts the extracted string ('1') to an integer (1).\n",
    "rand_long_df['Period'] = rand_long_df['Period_Raw'].str.extract('(\\\\d+)').astype(int)\n",
    "\n",
    "# --- Clean up and show final long format ---\n",
    "# We can drop the original 'Period_Raw' column now.\n",
    "rand_long_df = rand_long_df.drop(columns=['Period_Raw'])\n",
    "print(\"Final long format randomization data:\")\n",
    "print(rand_long_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23bce",
   "metadata": {},
   "source": [
    "# Calculation of Initial Disposition Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number screened successfully\n",
    "num_screened = ie_df['SubjectID'].nunique()\n",
    "print(f\"Total participants screened: {num_screened}\")\n",
    "\n",
    "# find number of screen failures\n",
    "screen_failures_df = ie_df[ie_df['SubjectStatus'].fillna('').str.upper() == 'SCREEN FAILURE']\n",
    "num_screen_failures = screen_failures_df['SubjectID'].nunique()\n",
    "print(f\"Number of screen failures: {num_screen_failures}\")\n",
    "\n",
    "# find the number of participants randomized\n",
    "num_randomized = num_screened - num_screen_failures\n",
    "print(f\"Number of randomized participants: {num_randomized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a794159",
   "metadata": {},
   "source": [
    "# Calculation of Dosed and Population Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a82d",
   "metadata": {},
   "source": [
    "## Find product each participant received for each period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3917887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare IE data (Create a clean map from SubjectID to SUBJID) ---\n",
    "# We select only the ID columns and remove any duplicate rows.\n",
    "# We also drop rows where SUBJID might be missing, as we need it for merging.\n",
    "# We ensure SUBJID is an integer to match rand_long_df.\n",
    "subject_map_df = ie_df[['SubjectID', 'SUBJID']].drop_duplicates().dropna(subset=['SUBJID'])\n",
    "subject_map_df['SUBJID'] = subject_map_df['SUBJID'].astype(int)\n",
    "print(\"SubjectID to SUBJID map prepared.\")\n",
    "print(subject_map_df.head())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare EC data (Filter for dosed events and extract Period from VISIT) ---\n",
    "# Filter for rows where ECYN is 'yes'. Use .copy() to avoid SettingWithCopyWarning.\n",
    "dosed_df = ec_df[ec_df['ECYN'].fillna('').str.lower() == 'yes'].copy()\n",
    "# Extract the period number from the 'VISIT' column using 'Period X' pattern.\n",
    "dosed_df['Period'] = dosed_df['VISIT'].str.extract('Period (\\\\d+)').astype(int)\n",
    "# Keep only SubjectID and Period, and drop duplicates (one row per subject per period dosed).\n",
    "dosed_df = dosed_df[['SubjectID', 'Period']].drop_duplicates()\n",
    "print(\"Dosed events (EC) prepared with correct Period:\")\n",
    "print(dosed_df.head())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge Dosing with Subject Map ---\n",
    "# Add SUBJID to our dosed_df by merging with subject_map_df.\n",
    "dosed_with_subjid = pd.merge(dosed_df, subject_map_df, on='SubjectID', how='left')\n",
    "print(\"Dosed data merged with SUBJID:\")\n",
    "print(dosed_with_subjid.head())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare for Merge: Check and Convert SUBJID types ---\n",
    "\n",
    "print(\"--- Preparing for Merge ---\")\n",
    "print(f\"dosed_with_subjid['SUBJID'] dtype before: {dosed_with_subjid['SUBJID'].dtype}\")\n",
    "print(f\"rand_long_df['SUBJID'] dtype before: {rand_long_df['SUBJID'].dtype}\")\n",
    "\n",
    "# 1. Drop rows where SUBJID might be missing in either DataFrame\n",
    "dosed_with_subjid.dropna(subset=['SUBJID'], inplace=True)\n",
    "rand_long_df.dropna(subset=['SUBJID'], inplace=True)\n",
    "\n",
    "# 2. Convert both SUBJID columns to integer type\n",
    "try:\n",
    "    dosed_with_subjid['SUBJID'] = dosed_with_subjid['SUBJID'].astype(int)\n",
    "    rand_long_df['SUBJID'] = rand_long_df['SUBJID'].astype(int)\n",
    "    print(f\"dosed_with_subjid['SUBJID'] dtype after: {dosed_with_subjid['SUBJID'].dtype}\")\n",
    "    print(f\"rand_long_df['SUBJID'] dtype after: {rand_long_df['SUBJID'].dtype}\")\n",
    "    print(\"SUBJID types standardized. Proceeding with merge.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error converting SUBJID to int: {e}\")\n",
    "    print(\"Please check the SUBJID columns in both DataFrames for non-numeric values.\")\n",
    "    # You might want to stop or handle the error here if conversion fails.\n",
    "    raise # Re-raise the error to stop execution if conversion fails\n",
    "\n",
    "# --- END Prepare for Merge ---\n",
    "\n",
    "\n",
    "# --- Merge with Randomization Data --- (Your original line)\n",
    "final_dosed_df = pd.merge(dosed_with_subjid, rand_long_df, on=['SUBJID', 'Period'], how='inner')\n",
    "\n",
    "# ... (The rest of your cell) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11417a8e",
   "metadata": {},
   "source": [
    "## Count dosed per treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Count Dosed per Treatment ---\n",
    "# Finally, group by the 'Treatment' column and count the unique SubjectIDs.\n",
    "dosed_per_treatment = final_dosed_df.groupby('Treatment')['SubjectID'].nunique()\n",
    "\n",
    "print(\"### Number of Participants Dosed Per Treatment ###\")\n",
    "print(dosed_per_treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c373d3",
   "metadata": {},
   "source": [
    "# Calculating Overall Completion and Discontinuation Counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ad47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate 'Completed' ---\n",
    "# Filter for 'Completed' status and count unique SubjectIDs.\n",
    "# We'll use .dropna() here to ensure we only count subjects with an ID.\n",
    "completed_df = ds_df[ds_df['SubjectStatus'].fillna('').str.upper() == 'COMPLETED']\n",
    "num_completed = completed_df['SubjectID'].dropna().nunique()\n",
    "print(f\"Number of completed participants: {num_completed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate 'Lost To Follow-Up' ---\n",
    "# Filter for 'Lost to Follow-up' status and count unique SubjectIDs.\n",
    "lost_df = ds_df[ds_df['SubjectStatus'].fillna('').str.upper() == 'LOST TO FOLLOW-UP']\n",
    "num_lost_to_follow_up = lost_df['SubjectID'].dropna().nunique()\n",
    "print(f\"Number Lost To Follow-Up: {num_lost_to_follow_up}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate Total 'Discontinued' ---\n",
    "# This should be the total randomized minus those who completed.\n",
    "# We use 'num_randomized' which we calculated back in Step 2.\n",
    "num_discontinued = num_randomized - num_completed\n",
    "print(f\"Total number discontinued: {num_discontinued}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505f812",
   "metadata": {},
   "source": [
    "# Assemble Data into the Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77cc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure we have all our numbers ---\n",
    "# These should exist from previous steps:\n",
    "# num_screened, num_screen_failures, num_randomized\n",
    "# dosed_per_treatment (this is a pandas Series, like TP1: 27, TP2: 27...)\n",
    "# num_completed, num_discontinued, num_lost_to_follow_up\n",
    "\n",
    "# --- Define the structure ---\n",
    "index_names = ['Screened', 'Screen Failure', 'Randomized',\n",
    "               'Included in Safety Population', 'Included in PK Population',\n",
    "               'Completed', 'Discontinued from study', '  Lost To Follow-Up']\n",
    "\n",
    "# Ensure 'Overall' is not in dosed_per_treatment, then get T names\n",
    "treatment_names = list(dosed_per_treatment.index)\n",
    "column_names = treatment_names + ['Overall']\n",
    "\n",
    "# --- Create the Data Dictionary ---\n",
    "data = {}\n",
    "\n",
    "# --- Populate Overall Column ---\n",
    "# The N for the 'Overall' column is the total number randomized\n",
    "overall_N = num_randomized\n",
    "data['Overall'] = [\n",
    "    num_screened,\n",
    "    num_screen_failures,\n",
    "    num_randomized,\n",
    "    num_randomized, # Safety N (Overall)\n",
    "    num_randomized, # PK N (Overall)\n",
    "    num_completed,\n",
    "    num_discontinued,\n",
    "    num_lost_to_follow_up\n",
    "]\n",
    "\n",
    "# --- Populate Treatment Columns ---\n",
    "for t_name in treatment_names:\n",
    "    n_t = dosed_per_treatment.get(t_name, 0) # Get N for this treatment\n",
    "    data[t_name] = [\n",
    "        np.nan, # Screened is only Overall\n",
    "        np.nan, # Screen Failure is only Overall\n",
    "        np.nan, # Randomized is only Overall (in this simple view)\n",
    "        n_t,    # Safety N for this treatment\n",
    "        n_t,    # PK N for this treatment\n",
    "        np.nan, # Completed is only Overall\n",
    "        np.nan, # Discontinued is only Overall\n",
    "        np.nan  # Lost to Follow-up is only Overall\n",
    "    ]\n",
    "\n",
    "# --- Create the DataFrame ---\n",
    "summary_df = pd.DataFrame(data, index=index_names)\n",
    "\n",
    "# --- Reorder columns to match image (TP1, TP2 ... RP, Overall) ---\n",
    "summary_df = summary_df[column_names]\n",
    "\n",
    "# --- Display the DataFrame with raw numbers ---\n",
    "print(\"### Participant Disposition Table (Raw Numbers) ###\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24deba13",
   "metadata": {},
   "source": [
    "# Formatting the summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define N for each column (base for percentages) ---\n",
    "# For treatment columns, N is the count from dosed_per_treatment.\n",
    "# For Overall, N is num_randomized.\n",
    "N_map = dosed_per_treatment.copy()\n",
    "N_map['Overall'] = num_randomized\n",
    "\n",
    "# --- Create an empty DataFrame with the same structure ---\n",
    "formatted_df = pd.DataFrame(index=summary_df.index, columns=summary_df.columns)\n",
    "\n",
    "# --- Rows that need percentages ---\n",
    "rows_with_pct = ['Included in Safety Population', 'Included in PK Population',\n",
    "                 'Completed', 'Discontinued from study', '  Lost To Follow-Up']\n",
    "\n",
    "# --- Loop through each cell and format it ---\n",
    "for col_name in summary_df.columns:\n",
    "    N = N_map.get(col_name, 0) # Get N for this column\n",
    "\n",
    "    for row_name in summary_df.index:\n",
    "        count = summary_df.loc[row_name, col_name]\n",
    "\n",
    "        # Check if the count is NaN (Not a Number)\n",
    "        if pd.isna(count):\n",
    "            formatted_df.loc[row_name, col_name] = \"\" # Make it blank\n",
    "        else:\n",
    "            count = int(count) # Convert to integer for display\n",
    "            # Check if this row should have a percentage\n",
    "            if row_name in rows_with_pct and N > 0:\n",
    "                pct = (count / N) * 100\n",
    "                formatted_df.loc[row_name, col_name] = f\"{count} ({pct:.1f}%)\"\n",
    "            else:\n",
    "                # If no percentage needed or N is 0, just show the count\n",
    "                formatted_df.loc[row_name, col_name] = f\"{count}\"\n",
    "\n",
    "# --- Format the column headers ---\n",
    "new_column_names = []\n",
    "for col in summary_df.columns:\n",
    "    n_val = N_map.get(col, 0)\n",
    "    new_column_names.append(f\"{col}\\n(N={n_val})\") # Add N and a newline\n",
    "\n",
    "formatted_df.columns = new_column_names\n",
    "\n",
    "# --- Display the final formatted table ---\n",
    "print(\"### Final Participant Disposition Table ###\")\n",
    "print(formatted_df.to_string()) # .to_string() helps display all rows/cols nicely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f177f09",
   "metadata": {},
   "source": [
    "# Generate Word Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml.ns import qn\n",
    "from docx.oxml import OxmlElement\n",
    "\n",
    "# --- Function to set specific borders (from DV.ipynb) ---\n",
    "def set_cell_borders(cell, **kwargs):\n",
    "    \"\"\"\n",
    "    Set cell's border (top, bottom, left, right, insideH, insideV).\n",
    "    Use {'val': 'nil'} to remove a border.\n",
    "    Use {\"sz\": 6, \"val\": \"single\", \"color\": \"000000\"} for a 0.75pt black line.\n",
    "    \"\"\"\n",
    "    tc = cell._tc\n",
    "    tcPr = tc.get_or_add_tcPr()\n",
    "    tcBorders = tcPr.first_child_found_in(\"w:tcBorders\")\n",
    "    if tcBorders is None:\n",
    "        tcBorders = OxmlElement('w:tcBorders')\n",
    "        tcPr.append(tcBorders)\n",
    "\n",
    "    for edge in ('top', 'left', 'bottom', 'right', 'insideH', 'insideV'):\n",
    "        edge_data = kwargs.get(edge)\n",
    "        if edge_data:\n",
    "            tag = f'w:{edge}'\n",
    "            border = tcBorders.find(qn(tag))\n",
    "            if border is None:\n",
    "                border = OxmlElement(tag)\n",
    "                tcBorders.append(border)\n",
    "\n",
    "            if edge_data.get(\"val\") == \"nil\":\n",
    "                border.set(qn('w:val'), \"nil\")\n",
    "                for att in [\"sz\", \"color\", \"space\", \"shadow\"]:\n",
    "                    if qn(f'w:{att}') in border.attrib:\n",
    "                        del border.attrib[qn(f'w:{att}')]\n",
    "            else:\n",
    "                for k, v in edge_data.items():\n",
    "                    border.set(qn(f'w:{k}'), str(v))\n",
    "\n",
    "# --- Check if formatted_df exists ---\n",
    "if 'formatted_df' in locals() and not formatted_df.empty:\n",
    "    try:\n",
    "        document = Document()\n",
    "        document.add_paragraph('Participant Disposition Table')\n",
    "        document.add_paragraph()\n",
    "\n",
    "        # --- Define Styles ---\n",
    "        font_name = 'Calibri'\n",
    "        font_size = Pt(10)\n",
    "        border_style = {\"sz\": 6, \"val\": \"single\", \"color\": \"000000\"}\n",
    "        no_border = {\"val\": \"nil\"}\n",
    "\n",
    "        # --- Add the Table (formatted_df.shape[1] + 1 for the new first column) ---\n",
    "        num_cols = formatted_df.shape[1] + 1\n",
    "        table = document.add_table(rows=formatted_df.shape[0] + 1, cols=num_cols)\n",
    "\n",
    "        # --- Header Row ---\n",
    "        column_headers = formatted_df.columns.tolist()\n",
    "        for j in range(num_cols):\n",
    "            cell = table.cell(0, j)\n",
    "            if j == 0:\n",
    "                # First column header is blank\n",
    "                header_text = \"\"\n",
    "                paragraph = cell.paragraphs[0]\n",
    "                run = paragraph.add_run(header_text)\n",
    "            else:\n",
    "                # Other headers (j-1 because column_headers doesn't include the first blank one)\n",
    "                header = column_headers[j-1]\n",
    "                # Handle headers with newlines (from N=xx)\n",
    "                if '\\\\n' in header:\n",
    "                     parts = header.split('\\\\n')\n",
    "                     cell.text = parts[0]\n",
    "                     for part in parts[1:]:\n",
    "                         cell.add_paragraph(part)\n",
    "                else:\n",
    "                     cell.text = header\n",
    "\n",
    "                # Format all paragraphs in the cell\n",
    "                for p in cell.paragraphs:\n",
    "                     run = p.runs[0]\n",
    "                     run.font.bold = True\n",
    "                     run.font.name = font_name\n",
    "                     run.font.size = font_size\n",
    "                     p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "            # Set header borders for all header cells\n",
    "            set_cell_borders(cell,\n",
    "                             top=border_style,\n",
    "                             bottom=border_style,\n",
    "                             left=no_border,\n",
    "                             right=no_border)\n",
    "\n",
    "        # --- Data Rows ---\n",
    "        num_data_rows = formatted_df.shape[0]\n",
    "        for i, row_name in enumerate(formatted_df.index):\n",
    "            for j in range(num_cols):\n",
    "                cell = table.cell(i + 1, j)\n",
    "                if j == 0:\n",
    "                    # First column: Row names (Category)\n",
    "                    cell_text = row_name.strip() # Use strip() to remove leading spaces for bold check\n",
    "                    paragraph = cell.paragraphs[0]\n",
    "                    run = paragraph.add_run(row_name) # Use original for spaces\n",
    "                    run.font.name = font_name\n",
    "                    run.font.size = font_size\n",
    "                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "                    # Handle indentation for 'Lost To Follow-Up'\n",
    "                    if row_name.strip().startswith(\"Lost\"):\n",
    "                         paragraph.paragraph_format.left_indent = Inches(0.25)\n",
    "\n",
    "                else:\n",
    "                    # Other columns: Data (j-1 to access formatted_df)\n",
    "                    cell_text = str(formatted_df.iloc[i, j-1])\n",
    "                    paragraph = cell.paragraphs[0]\n",
    "                    run = paragraph.add_run(cell_text)\n",
    "                    run.font.name = font_name\n",
    "                    run.font.size = font_size\n",
    "                    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "                # Set data row borders (Only bottom border for the *last* row)\n",
    "                border_args = {\"left\": no_border, \"right\": no_border, \"top\": no_border, \"bottom\": no_border}\n",
    "                if (i + 1) == num_data_rows: # If it's the last data row\n",
    "                    border_args[\"bottom\"] = border_style\n",
    "\n",
    "                set_cell_borders(cell, **border_args)\n",
    "\n",
    "        # --- Save the Document ---\n",
    "        file_path = \"outputs/Summary of Participant Disposition.docx\"\n",
    "        document.save(file_path)\n",
    "        print(f\"Word document '{file_path}' created successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the Word document: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Formatted DataFrame ('formatted_df') is empty or not defined. Cannot create Word document.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
